# Intorduction_to_airflow


 positional arguments:

  dag_id                The id of the dag

  task_id               The id of the task

  execution_date        The execution date of the DAG
  
  
  test python operator for fetching tweet
  
  # airflow test twitter_dag fetching_tweet_task 2020-10-01
  
  
  test python operator for cleaning
  
  # airflow test twitter_dag cleaning_tweets 2020-10-01
  
 ## Before Running Bash and Hive Operator:
  
  # Run hive_table_tweets.hql file in Hive to register your schema and create table if not exists 

